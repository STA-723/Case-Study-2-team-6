---
title: "Case study 1: Effect of chemical exposures on preterm birth"
author: 
- name: Olivier Binette, Brian Kundinger and Justin Weltz
date: 'January 23, 2020'
abstract: "abstract"
output: 
  pdf_document:
    keep_tex: true
    fig_caption: true
    latex_engine: pdflatex
    template: svm-latex-ms.tex
    citation_package: natbib
header-includes:
  - \usepackage{hyperref}
linestretch: 1
link-citations: yes
linkcolor: blue
fontfamily: mathpazo
fontsize: 10pt
bibliography: biblio.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(tidyverse)
library(cowplot)
library(BAS)
source("prettyplot.R")
```

# 1. Introduction


## 1.1 Dataset and its limitations



# 2. Materials and methods

## 2.2 Data cleaning and transformation

TODO: OB

## 2.3 Text analysis
We can see that the study uses a different number of total months for each listing when calculating "average reviews per month."
```{r}
data_transformed %>% 
  filter(id == c(5447434, 30232758)) %>% 
  select(id, number_of_reviews, last_review, reviews_per_month)
```

$$\frac{\text{Days between July 8, 2019 and Last Review}}{30.42} = \text{Months Inactive} $$
$$\frac{\text{No. of Reviews}}{\text{Months Active + Months Inactive}} = \text{Reviews per Month}$$
$$\text{Months Active} = \min \left\{\frac{\text{No. of Reviews - (Reviews per Month)(Months Inactive)}}{\text{Reviews per Month}}, 1\right\}$$
$$\text{Normalized Average Reviews} = \frac{\text{Total Reviews}}{\text{Months Active}}$$

Through normalization, we recover the popularity of each listing during the time it was active. 
```{r}
data_transformed %>% 
  filter(id == c(5447434, 30232758)) %>% 
  select(id, number_of_reviews, last_review, reviews_per_month, nrml_avg_reviews)
```



```{r}

text_model <- lm(nrml_avg_reviews~ . , data = data_transformed[, -c(1:6, 7:18, 20:21)])

pvalues <- data.frame(summary(text_model)$coefficients[,4])
words <- names(coef(text_model))
toplist <- as.data.frame(cbind(words, pvalues))
colnames(toplist) <- c("words", "pvalues")

toplist %>% 
  arrange(pvalues) %>% 
  filter(pvalues<0.05/219)
```

TO SHOW NO STAYS AT HIGH PRICES
```{r}
raw_data <- read.csv("AB_NYC_2019.csv")
  
raw_data %>%
  mutate(quantile = ntile(price, 10)) %>%
  mutate(no_stay = number_of_reviews==0) %>% 
  group_by(quantile) %>%
  count(no_stay==1)%>% 
  mutate(prop = prop.table(n))%>% 
  ggplot(aes(x = quantile, y = prop, fill = `no_stay == 1`)) + geom_bar(stat = 'identity', position = 'dodge', alpha = 2/3) + geom_hline(yintercept = mean(raw_data$number_of_reviews == 0))
```


## 2.4 Additional data

TODO: OB

## 2.5 CAR and glm models for neighborhood effect controlling for distance

- Neighborhood effect controlling for distance

- CAR model

- Hierarchical model
```{r}
require(car)
model_heir <- lmer(nrml_avg_reviews~ (1|neighbourhood_group/neighbourhood)+price +dist_to_subway, data = data_transformed)
summary(model_heir)
Anova(model_heir)
coef(model_heir)

```

## 2.6 Global hierarchical model to compare effects of different features

- Keyword importance
    - Take the 5 most important ones to feed in the RF.

- Global hierarchical model

- With all variables (excepted distance)


# 3. Results

- Graphical display of the results

- OB can help with the graphical display


# 4. Discussion


# Appendix

## EDA
TODO: OB

