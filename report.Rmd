---
title: 'Case study 2: New York Airbnb listings'
author:
- name: Olivier Binette, Brian Kundinger and Justin Weltz
date: "January 23, 2020"
output:
  pdf_document:
    citation_package: natbib
    fig_caption: yes
    keep_tex: yes
    latex_engine: pdflatex
    template: svm-latex-ms.tex
  html_document:
    df_print: paged
header-includes: \usepackage{hyperref}
linestretch: 1
link-citations: yes
linkcolor: blue
fontfamily: mathpazo
fontsize: 10pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

library(tidyverse)
library(cowplot)
library(BAS)
source("prettyplot.R")
library(RColorBrewer)
library(ggmap)
library(car)
library(MASS)
```

```{r, include=FALSE}
data <- readRDS("data_transformed.rds")
```

# 1. Introduction

Airbnb is a online marketplace of rooms, houses and appartments to rent for short periods of time, as an alternative to hotels and other accomodation services. Having started just around 2008, the growth of Airbnb has been phenomenal. Now more than 6 million listings are available worldwide.

This case study focuses on New York City 2019 listings compiled by Murray Cox as part of the Inside Airbnb project, originally with the goal of supporting thoughtful debate surrounding the socio-economic impact of this growing business. We study this data more superficially, focusing on (1) the neighborhood brand effects on listing popularity; and (2) how different listing features are associated with popularity.

Our measure of popularity is defined as the monthly number of reviews per month, properly normalized to account for disrepancy in the data (see Section 2.2). A conditional auto-regressive spatial model is used to assess neighborhood brand effect (Section 2.4), while a global additive model allows us to extract conditional trends related to listing popularity (Section 2.5). The results of our analyses are presented in Section 3, supported with Figures listed in the Appendix. We reflect more broadly on the problem in Section 4.

# 2. Materials and methods

## 2.1 Data

The \texttt{Airbnb} dataset contains $48\,895$ listings from New York City which have been active before July 8, 2019. Information is given on the name of the listing, the name of of the host, the type of room available (entire home, private room or shared room), on the minimum number of nights for a rental, on the yearly availability, on the location of the listing (coordinates and neighborhood), on its price, on the number of reviews, and on the average number of reviews per months.

We note that $35\%$ of the listings are recorded as having zero availability for booking. It is unclear in these cases if the listing is fully booked, or if it is simply no longer available for booking and has been temporarily disabled. Furthermore, the listed availability may have changed throughout time, and we are only provided with its value at the time when the data was collected. We do not use this variable in our analyses given these challenges in interpretability.

## 2.2 Data cleaning and transformations

Among the listings requiring stays of longer lengths of time, it was often unclear whether the price listed was a monthly, weekly, or daily price. We focus our analysis on listings which can be rented for less than 7 nights. Additionally, listings which had recieved no reviews had relatively high prices in comparison with the rest of the data set. Since listings that had recieved no reviews were not representative of the active listings, we removed these listings from our analysis. Lastly, we remove 11 listings that are priced at more than five thousands dollars a night. Many of these were event spaces or film and photography venues, and thus were not representative of typical Airbnb listing. We thus conducting our analysis with 32819 data points representing typical listings which can be rented for a few nights at a non-extravagant price.

As a measure of popularity, we consider a normalized average number of review per months. Indeed, it appears that the average number of review per months has been computed including the months a listing has been inactive. We have therefore renormalized the average by removing on the denominator the number of months since the last time a listing received a review.

## 2.3 Computed features

The Airbnb dataset was augmented with the following features:

**1. Text analysis.** $\;$ We extracted all adjectives from the listing names and kept those with a frequency of at least 10. We then ran a linear regression of average reviews against these words, and identified all words with p-values below the Bonferonni adjustment of $\frac{0.05}{218}$. This left 18 words for further analysis, and the data has been augmented to contain indicators of the presence or absence of each of these words.

Of important note, some of the words picked up by our algorithms are most likely not adjectives in the context of this dataset. For example, "apt" is most likely a shortening of "apartment," and not an adjective meaning "correct," and minute is most likely a measurement of time and proximity, and not an adjective meaning "small." We choose however to retain these words for the purpose of this analysis.

**2. Distances to subway stations.** $\;$ We computed distance between listings and the nearest subway entrance using data from [New York's Open Data portal](https://data.cityofnewyork.us/Transportation/Subway-Entrances/drex-xx56).

**3. Gender imputation.** $\;$ We imputed hosts gender using data in the R package \texttt{genderdata} through the interface package \texttt{gender}. Host names were compared with records from the U.S. Social Security Administration, and imputation was made when there was more than $90\%$ match to a given gender. Otherwise, such as when the host name consisted of a pair of person, an "Unknown" gender was recorded.


## 2.4 Conditional autoregressive model to assess neighborhood effect on popularity

In order to advise a new Airbnb owner on the best neighborhood to set up a property, we have to be careful to separate the neighborhood effect on popularity from auto-correlation over the spatial dimension. For example, figure 1 and 2 demonstate two density patterns that would make an analysis of neighborhood popularity without controlling for distance problematic. The Theater District in New York City includes Times Square and many other major tourist attractions. In figure 1, we can see that most of the Airbnb locations in Hell's Kitchen are concentrated next to the Theater Disctrict, meaning that the measured effect on popularity of being in the latter nieghborhood may be inflated because it is highly correlated with the desirability of the theater district. Figure 2, depicts another interesting density pattern. We can see that although there are many Airbnb locations on the outskirts of Chinatown, there are very few in the heart of the neighborhood. This could cause Chinatown's popularity coefficient to be closely correlated with the neighborhoods that surround it. If we observe high popularity in this neighborhood and then advise a new Airbnb owner with this information, they could make a large strategic blunder by placing their property in middle of the neighborhood. This seems problematic!

Therefore, we will account for the density of Airbnb locations so that we can measure the "name brand effect" of neighborhoods on popularity. In order to control for the distance between properties, we will use the conditionally auto-regressive model proposed by Lareaux et al. in "Estimation of Disease Rates in Small Areas: A New Mixed Model for Spatial Dependence." This Bayesian approach models spatial auto-correlation as a smooth function of distance using an adjacency matrix and a series of priors on distance effects specified below:

$$\phi_k| \phi_{-k}, W, \tau^2, \rho \sim N(\frac{\rho\sum_{i=1}^k w_{ki}\phi_i}{\rho\sum_{i=1}^k w_{ki} + 1-\rho}, \frac{\tau^2}{\rho\sum_{i=1}^k w_{ki} + 1-\rho})$$

$$\tau^2 \sim Inverse-Gamma(a,b)$$
$$\rho \sim Uniform(0,1)$$

We deternmine the distance between neighbours so that every property has a neighbor and the mean number of neighbours is around 30. The correlation between neighbor's spatial effects is determined by the equation below, where $\rho$ is a global parameter that determines the smoothing of the auto-correlation function (aka the magnitude and decay of correlation between neighboring properties). 

$$CAR(\phi_k, \phi_j | \phi_{-kj}, W, \rho) = \frac{\rho w_{kj}}{\sqrt{(\rho \sum_{i=1}^k w_{ki} + 1 - \rho)(\rho \sum_{i=1}^k w_{ki} + 1 - \rho }}$$

Unfortunately, since the CAR model take a very long time to run on large datasets, we weren't able to model this spatial relationship for every observation and ended up running seperate analyses on each of the boroughs with 1000 randomly selected observations (in each borough). Lastly, we also controlled for price and distance to subway when measuring neighborhood effects in this model.

## 2.5 Global additive model for feature effects

We compare the effect of the different given and computed features of the dataset using a log-linear additive model. Using standard $R$ formula representation, our model is therefore
\begin{align*}
  \log(\texttt{monthly reviews}) \sim &\overbrace{f_1(\texttt{price}) + f_2(\texttt{dist to subway}) + f_3(\texttt{months active})}^{\text{continuous variables}} \\
  &+ \underbrace{\texttt{entire home/apt} + \texttt{female} + \texttt{round_price}}_{\text{binary features}} + \underbrace{\texttt{private} + \cdots + \texttt{cozy}}_{keywords}\\
  &+ \texttt{neighbourhoods}
\end{align*}
where $f_1$, $f_2$ and $f_3$ are increasing functions, and we assume a normal error distribution. The variables $\texttt{entire home/apt}$, $\texttt{female}$ and $\texttt{round_price}$ are indicators that the listing is an entire home/apt, that the host is thought to be female, and that the price of the listing is a multiple of $50$. The "keyword" variables are indicators that the title contains the words identified by our text analysis, and finally the baseline effect of the neighborhood factor is controlled.

The functions $f_1$, $f_2$ and $f_3$ are Box-Cox transformations of the form $f(x) = (x^{\lambda}-1)/\lambda$ and are estimated by maximum likelihood using the \texttt{boxTidwell} function of the \texttt{car} package. We also tried using monotonicity-constrained splines as implpemented in the shape constrained generalized additive model packages \texttt{cgam} and \texttt{scam}, but these took too long to run on our machines.

This log-linear additive model, with monotonically transformed continuous variables, provides us with easily interpretable estimates of linear trends.

```{r, cache=TRUE}
data <- readRDS("data_transformed.rds")
data = data %>% filter(price != 0)

model.full = lm(log(nrml_avg_reviews) ~ log(price) + log(dist_to_subway) + months_active + room_type + gender + private + square + minute + close + stock + apt + sunny + spacious + deluxe + newly + walking + cozy + central + fast + huge + west + green + neighbourhood, data=data)
```

```{r, cache=TRUE, warning=FALSE, message=FALSE}
bx = boxTidwell(log(nrml_avg_reviews) ~ price + dist_to_subway + months_active, 
           other.x= ~ room_type + gender + 
             private + square + minute + close + stock + apt + 
             sunny + spacious + deluxe + newly + walking + cozy + 
             central + fast + huge + west + green + neighbourhood, 
           data=data, max.iter=5, tol=0.01)
```

```{r, cache=TRUE}
bx_fun <- Vectorize(function(x, lambda) {
  return((x^(lambda)-1)/lambda)
})

data = data %>% mutate(round_price = price %in% seq(25, 5000, by=25),
                       female_host = (gender=="Female"))

model.bx = lm(log(nrml_avg_reviews) ~ bx_fun(price, 0.57422) + bx_fun(dist_to_subway, 0.83087) + bx_fun(months_active, -0.27567) + entire_home + female_host + round_price + private + square + minute + close + stock + apt + sunny + spacious + deluxe + newly + walking + cozy + central + fast + huge + west + green + neighbourhood, data=data %>% mutate(entire_home= room_type == "Entire home/apt"))
```


```{r}
# Multiplicative effects as a function of quantiles
plot_coef <- function(model, name, values, col=1, add=FALSE, ...) {
  coef_est = c(coef(model)[name], confint(model)[name,])

  coef_effect <- Vectorize(function(q) {
    c(exp(coef_est[1]*quantile(values, q))/exp(coef_est[1]*quantile(values, 0.5)),
      exp(coef_est[2]*quantile(values, q))/exp(coef_est[2]*quantile(values, 0.5)),
      exp(coef_est[3]*quantile(values, q))/exp(coef_est[3]*quantile(values, 0.5)))
  })
  
  q = seq(0,0.99,length.out = 200)
  coef_curve = coef_effect(q)
  
  if(add == FALSE) {
    fun=plot
  } else {
    fun=lines
  }
  
  fun(q, coef_curve[1,], type="l", lwd=2, col=col,
      xlab="Quantile",
     ylab="Multiplicative effect vs median",
     ...)
  polygon(c(q, rev(q)), c(coef_curve[2,], rev(coef_curve[3,])), border=NA, 
        col=adjustcolor(cmap.knitr(col), alpha.f=0.2))
}
```

# 3. Results

## 3.1 Neighborhood effects

Figure 3, which depicts the $\rho$ parameter for each borough, clearly indicates that spatial auto-correlation is present in the dataset even after accounting for neighborhood effects. Even though figures 4-7 indicated a lot of diversity in effects and effect sizes based on neighborhoods, there are only a few coefficients whose $95\%$ posterior credible intervals do not include zero. Only Schuresville and Eastchester in the Bronx (figure 4) and Jamaica Hills and East Elmhurst in Queens (figure 6) have a "significant" effect. Since Queens has the highest popularity intercept and East Elmhurt has a significant positive effect on top of this baseline, it seems like this is the best location for a new Airbnb owner to locate his property! However, overwhelming, the effect of neighbourhoods controlling for distance seems to be negligible. This finding may be the result of NYC's highly interconnected and effecient transit system, which enables visitors to travel to major destinations with ease regardless of their starting point.


## 3.2 Feature effects

The global log-linear additive model provides estimates of trends associating features to listing popularity, after accounting for neighborhood baseline effects and other factors. In the left panel below, we see the estimated multiplicative effect of the continuous variables on popularity compared to the median point of the dataset, as a function of the quantiles of this variable. For instance, looking at the price in blue, we see that lower prices correspond to slighly higher popularity (multiplicative effect relative to median $> 1$), while higher prices are slightly less popular. Here, price and distance to subway have very small effects, while the number of months a listing has been active has a much higher effect on popularity.

On the right, we see that certain keywords (e.g. "stock", "fast", "minute", "walking", "central") are associated with more popular listings, while others ("spacious", "sunny", "apt", "huge") are associated with less popular ones. Notable, round priced listings (price a multiple of $50$) are less popular, and female hosts' listings are also associated with a slightly smaller average number of reviews per month.

```{r, fig.width=8, fig.height=3}
library(grid)
library(gridBase)
library(ggplot2)

# start new page
plot.new() 

# setup layout
gl <- grid.layout(nrow=1, ncol=2)
# grid.show.layout(gl)

# setup viewports
vp.1 <- viewport(layout.pos.col=1, layout.pos.row=1) 
vp.2 <- viewport(layout.pos.col=2, layout.pos.row=1) 
# init layout
pushViewport(viewport(layout=gl))
# access the first position
pushViewport(vp.1)

# start new base graphics in first viewport
par(new=TRUE, fig=gridFIG(), mar=c(3,3,1,1))

par(cex.lab=0.85)
plot_coef(model.bx, "bx_fun(price, 0.57422)", bx_fun(data$price, 0.57422), ylim=c(0.8,1.6),
          cex=0.5, cex.axis=0.7)
plot_coef(model.bx, "bx_fun(dist_to_subway, 0.83087)", bx_fun(data$dist_to_subway, 0.83087), 
          add=T, col=2)
plot_coef(model.bx, "bx_fun(months_active, -0.27567)", 
          bx_fun(data$months_active, -0.27567), 
          add=T, col=3)

abline(h=1, col=cmap.knitr(0), lty=2)

legend("topright", legend=c("price", "dist_to_subway", "months_active"), lty=c(1,1,1),
       col=c(cmap.knitr(1), cmap.knitr(2), cmap.knitr(3)), cex=0.7)


# done with the first viewport
popViewport()

# move to the next viewport
pushViewport(vp.2)


keywords = c("round_price", "entire_home", "female_host", "private", "square", "minute", "close", "stock", "apt", "sunny", 
             "spacious", "deluxe", "newly", "walking", "cozy", "central", 
             "fast", "huge", "west", "green")
effects = exp(as.numeric(coef(model.bx)[paste0(keywords, "TRUE")])) %>% round(3)
confints = confint(model.bx, parm=paste0(keywords, "TRUE"))

order = order(effects)


ggplotted = ggplot() +
  geom_col(mapping=aes(x=reorder(keywords, -effects), y=effects-1)) + 
  geom_linerange(aes(x=reorder(keywords, -effects), ymin=confints[,1], ymax=confints[,2])) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45))+
  scale_y_continuous(labels = function(y) y + 1)+
  ylab("Multiplicative effect on popularity") +
  xlab("Keywords and factors")


# print our ggplot graphics here
print(ggplotted, newpage = FALSE)

# done with this viewport
popViewport(1)
```


# 4. Discussion




# Appendix

## Proportion of Never Reviewed Listings by Price Decile 

```{r, echo=FALSE, warning=FALSE, fig.height=5}
raw_data <- read.csv("AB_NYC_2019.csv")
  
raw_data %>%
  mutate(quantile = ntile(price, 10)) %>%
  mutate(no_stay = number_of_reviews==0) %>% 
  group_by(quantile) %>%
  count(no_stay == 1)%>% 
  rename(Never_reviewed = `no_stay == 1`) %>% 
  mutate(prop = prop.table(n))%>% 
  ggplot(aes(x = quantile, y = prop, fill = Never_reviewed)) + geom_bar(stat = 'identity', position = 'dodge', alpha = 2/3) + geom_hline(yintercept = mean(raw_data$number_of_reviews == 0)) + ggtitle("Proportion of Never Reviewed by \n Price Decile")+ xlab("Price Decile") + ylab("Proportion")+theme(plot.title = element_text(hjust = 0.5))
```

<!--
## Normalized Average Reviews Formula

$$\frac{\text{Days between July 8 2019 and Last Review}}{30.42} = \text{Months Inactive} $$
$$\frac{\text{No. of Reviews}}{\text{Months Active + Months Inactive}} = \text{Reviews per Month}$$
$$\text{Months Active} = \frac{\text{No. of Reviews - Avg Reviews*Months Inactive}}{\text{Reviews per Month}}$$
$$\text{Normalized Average Reviews} = \frac{\text{Total Reviews}}{\text{Months Active}}$$

\begin{table}[ht]
\centering
\begin{tabular}{rrrrr}
  \hline
 & id & No.\_reviews & last\_review & Avg\_reviews & Nrmlized\_reviews\\ 
  \hline
1 & 5447434 &  20 & 2016-01-03 & 0.41 & 2.86 \\ 
  2 & 30232758 &  20 & 2019-07-02 & 2.84 & 2.84\\ 
   \hline
\end{tabular}
\end{table}
-->

## Spatial Auto-correlation and CAR Model

```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap= "Theater District"}
data <- readRDS("data_transformed.rds")
data %>% filter( neighbourhood == "Theater District" |neighbourhood == "Hell's Kitchen") %>% ggplot(aes(x  = latitude, y = longitude, color = neighbourhood)) + stat_density2d() + theme(legend.position = "none") + ggtitle("Hell's Kitchen and Theater District Density")


```

```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap= "Chinatown"}

data %>% filter(neighbourhood == "Chinatown") %>% ggplot(aes(x  = latitude, y = longitude)) + stat_density2d() + theme(legend.position = "none") + ggtitle("Chinatown Density")

```


## CAR Model Results

```{r, warning=FALSE, message=FALSE, echo= FALSE, fig.cap="Rho Coefficients"}

data_r <- rbind(c("rho", 0.9072, "Bronx"), c("rho", 0.9277, "Manhattan"),  c("rho", 0.7474, "Queens"), c("rho", 0.7389, "Brooklyn"))
data_r <- data.frame(data_r)
names(data_r) <- c("Variables", "Value", "Borough")
data_r  %>% ggplot(aes(x=Borough,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Rho Coefficients")

```



```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Bronx"}

data <- readRDS("Coefficient_Data.rds")

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Bronx") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Bronx Coefficients (Reference: Allerton)")

```


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= "Manhattan"}

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Manhattan") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Manhattan Coefficients (Reference: Battery Park City)")
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Queens"}

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Queens") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Queens Coefficients (Reference: Arverne)")
```


```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.cap= "Brooklyn"}

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Brooklyn") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1))+ ggtitle("Brooklyn Coefficients (Referene: Bath Beach)")
data <-readRDS("data_transformed.rds")
```

## EDA

We first look at a map of the airbnb listings over New York.

```{r, message=FALSE, echo=FALSE, warning=FALSE, cache=TRUE}
register_google(key="AIzaSyDnqUXoVEle0J7gGGZQcdV5HQeQEGRlxLQ")

map_coarse = get_stamenmap(c(left=-74.25, right=-73.5, bottom=40.49, top=41), 
              zoom=10,
              maptype="terrain-background",
              #maptype="toner-background",
              color="bw", force=TRUE)
```

```{r, fig.width=3, fig.height=3, fig.align="center"}
ggmap(map_coarse) +
  geom_point(data=data, aes(x=longitude, y=latitude), 
             size=0.1, alpha=0.5,
             color="black") +
  stat_density2d(data=data, aes(x=longitude, y=latitude,
                                fill=..level.., alpha=..level..), 
                 geom="polygon") +
  guides(alpha = FALSE, fill=FALSE) +
  scale_fill_gradient((brewer.pal(7, "Spectral"))) +
  xlim(-74.15, -73.7) +
  ylim(40.55, 40.91) +
  theme_void()
```

## Neighborhood concentration

```{r, fig.width=3, fig.height=3, fig.align="center"}
data %>% ggplot(aes(x=nrml_avg_reviews, color=gender)) +
  geom_density() +
  theme_minimal()
```


```{r, fig.width=3, fig.height=3, fig.align="center"}
ggplot() +
  geom_hex(data=data, aes(x=longitude, y=latitude, fill=price))+
  xlim(-74.2, -73.65) +
  ylim(40.5, 40.95) +
  theme_void()
```
