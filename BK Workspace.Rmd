---
title: "BK Workspace"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(corrgram)
require(corrplot)
require(lubridate)
require(quanteda)
require(stringr)
require(readr)
require(lme4)
require(tidytext)
require(ggplot2)
require(textdata)

```

Normalized Reviews per Month

I figured that reviews_per_month was a better metric than total reviews to measure popularity, but saw that reviews_per_month penalized listings that have been inactive for long periods of time. Run this chunk to see how "normalized average reviews" adjusts for that. Woot woot :)
```{r}
data <- read_csv("AB_NYC_2019.csv")

data <- data %>% 
  mutate(last_review = ymd(last_review)) %>% 
  mutate(months_inactive = round(as.numeric(ymd("2019-07-08") - last_review)/30.42)) %>% 
  mutate(months_active = (number_of_reviews - reviews_per_month*months_inactive)/reviews_per_month) %>% 
  mutate(months_active = case_when(
    months_active >=1 ~ months_active, 
    months_active <1 ~ 1
  )) %>% 
  mutate(nrml_avg_reviews = case_when(
    reviews_per_month>0 ~ number_of_reviews/months_active, is.na(reviews_per_month) ~ 0)) %>% 
  filter(minimum_nights <14 & number_of_reviews!=0)

```

INVESTIGATING PRICE
```{r}
data %>% 
  arrange(minimum_nights, price) %>% 
  select(minimum_nights, price) %>% 
  distinct()
```


TEXT ANALYSIS SCRATCH WORK
```{r}
#Length of name (in characters)
str_length(data$name)
# str_detect(data$name, "[*!]")
# str_detect(data$name, "^[:upper:]+$")


#str_count(data$name, "[:upper:]")/str_length(data$name)

corpus_data <- corpus(data$name)
tokens_data <- tokens(corpus_data, remove_punct = TRUE)
tokens_data_pad <- tokens_remove(tokens_data, pattern = stopwords('en'))
head(tokens_data_pad)

tokens_dfm<- dfm(tokens_data_pad)
topfeatures(tokens_dfm, 20)
textstat_frequency(tokens_dfm)




#Tidy Text
data_text_analyis <- data %>% 
  mutate(name = str_to_lower(name, locale = "en"))
data_text_analyis$name


data("stop_words")
text <- data_text_analyis$name
text_df <- tibble(line = 1: dim(data)[1], text=text)

tidy_text <- text_df %>% 
  unnest_tokens(word, text) %>% 
  anti_join(stop_words) 

tidy_text_adj <- tidy_text %>% 
  left_join(parts_of_speech) %>%
  filter(pos %in% c("Adjective","Adverb")) %>%
  pull(word) %>%
  unique

tidy_text %>% 
  count(word, sort = TRUE)

tidy_text %>%
  count(word, sort = TRUE) %>%
  filter(n > 2000) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

get_sentiments("afinn")
bing <- get_sentiments("bing")


#CREATING INDICATORS

pattern <- paste(tidy_text_adj, collapse = "|")

dt <- data.frame(
  ItemNames = c("Superb apple", "Superb Pear", "Superb car"), 
  Cost = c(1, 2, 3),
  stringsAsFactors = FALSE
)
for(i in 1:length(tidy_text_adj)){
index <- str_detect(tidy_text_adj[i], regex(pattern))
data[index,]$name
}
adjectives.matrix <- matrix(NA, nrow = dim(data)[1], ncol = 788)

for(i in 1:788){
  adjectives.matrix[,i] <- str_detect(data_text_analyis$name, tidy_text_adj[i])
}
View(adjectives.matrix)
View(data_text_analyis)

colnames(adjectives.matrix) <- tidy_text_adj
View(adjectives.matrix)

mega_data <- cbind(data, adjectives.matrix)

View(mega_data)
dim(mega_data)
model <- lm(data=mega_data[,19:807], nrml_avg_reviews ~ .)
summary(model)
```




MODEL SCRATCH WORK
```{r}
require(brms)
library(car)

fit <- brm(nrml_avg_reviews~ price+room_type + (1|neighbourhood) + (1|neighbourhood_group), data = data, family = "gaussian")


model <- lmer(nrml_avg_reviews~ (1|neighbourhood_group/neighbourhood) + price + room_type, data = data,  REML = FALSE)
summary(model)
Anova(model)
plot(model)
coef(model)
anova(model)

data %>% 
  group_by(neighbourhood_group) %>% 
  count(is.na(reviews_per_month))

?lmer
```

