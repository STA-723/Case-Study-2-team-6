---
title: "BK Workspace"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(corrgram)
require(corrplot)
require(lubridate)
require(quanteda)
require(stringr)
require(readr)
require(lme4)
require(tidytext)
require(ggplot2)
require(textdata)

```

Normalized Reviews per Month

I figured that reviews_per_month was a better metric than total reviews to measure popularity, but saw that reviews_per_month penalized listings that have been inactive for long periods of time. Run this chunk to see how "normalized average reviews" adjusts for that. Woot woot :)
```{r}
data <- read_csv("AB_NYC_2019.csv")

data <- data %>% 
  mutate(last_review = ymd(last_review)) %>% 
  mutate(months_inactive = round(as.numeric(ymd("2019-07-08") - last_review)/30.42)) %>% 
  mutate(months_active = (number_of_reviews - reviews_per_month*months_inactive)/reviews_per_month) %>% 
  mutate(months_active = case_when(
    months_active >=1 ~ months_active, 
    months_active <1 ~ 1
  )) %>% 
  mutate(nrml_avg_reviews = case_when(
    reviews_per_month>0 ~ number_of_reviews/months_active, is.na(reviews_per_month) ~ 0)) %>% 
  filter(minimum_nights <14 & number_of_reviews!=0)

```

INVESTIGATING PRICE
```{r}
data %>% 
  arrange(minimum_nights, price) %>% 
  select(minimum_nights, price) %>% 
  distinct()
```


TEXT ANALYSIS SCRATCH WORK
```{r}
#Length of name (in characters)
str_length(data$name)
# str_detect(data$name, "[*!]")
# str_detect(data$name, "^[:upper:]+$")


#str_count(data$name, "[:upper:]")/str_length(data$name)

corpus_data <- corpus(data$name)
tokens_data <- tokens(corpus_data, remove_punct = TRUE)
tokens_data_pad <- tokens_remove(tokens_data, pattern = stopwords('en'))
head(tokens_data_pad)

tokens_dfm<- dfm(tokens_data_pad)
topfeatures(tokens_dfm, 20)
textstat_frequency(tokens_dfm)




#ADJECTIVES MATRIX
library(tidytext)
library(textdata)

data("stop_words")

data_text_analysis <- tolower(data$name)
text <- data_text_analyis$name
text_df <- tibble(line = 1: dim(data)[1], text=text)

tidy_text <- text_df %>%  #Remove Stop Words
  unnest_tokens(word, text) %>% 
  anti_join(stop_words) 

tidy_text_adj <- tidy_text %>% #Identify words with frequency >= 10
  left_join(parts_of_speech) %>%
  filter(pos %in% c("Adjective","Adverb")) %>% 
  count(word, sort= TRUE) %>% 
  filter(n >=10) %>% 
  pull(word)

#Adjective matrix
adj_matrix <- matrix(NA, nrow = dim(data)[1], ncol = 226)

for(i in 1:226){
  adj_matrix[,i] <- str_detect(data_text_analyis$name, tidy_text_adj[i])
}

colnames(adj_matrix) <- tidy_text_adj

mega_data <- cbind(data, adjectives.matrix)

View(mega_data)
dim(mega_data)
model <- lm(data=mega_data[,19:807], nrml_avg_reviews ~ .)
summary(model)
```




MODEL SCRATCH WORK
```{r}
require(brms)
library(car)

fit <- brm(nrml_avg_reviews~ price+room_type + (1|neighbourhood) + (1|neighbourhood_group), data = data, family = "gaussian")


model <- lmer(nrml_avg_reviews~ (1|neighbourhood_group/neighbourhood) +price + room_type, data = data,  REML = FALSE)
summary(model)
Anova(model)
plot(model)
coef(model)
anova(model)

data %>% 
  group_by(neighbourhood_group) %>% 
  count(is.na(reviews_per_month))

?lmer
```

