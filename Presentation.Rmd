---
title: "Popularity of NYC Airbnb Listings"
author: "Olivier Binette, Justin Weltz, and Brian Kundinger"
output: 
  beamer_presentation
---
```{r, echo=FALSE, warning=FALSE, fig.height=5, include = FALSE}
chooseCRANmirror(graphics=FALSE, ind=1)
knitr::opts_chunk$set(echo = TRUE)
require(dplyr)
require(ggplot2)
require(quanteda)
require(tidytext)
require(lme4)
require(car)
require(lme4)
require(jtools)
```

## The Data

### Goal:

## Data cleaning and transformations
Listings with "minimum stay" greater than 30 often had extremely high prices, suggesting some were monthly prices. To avoid these innacuracies, we limit analysis to listings with "minimum stay" less than 7. 

Listings with high prices have no reviews at disporportionately high rates. Therefore, we remove listings with no reviews from our analysis.
```{r, echo=FALSE, warning=FALSE, fig.height=5}
raw_data <- read.csv("AB_NYC_2019.csv")
  
raw_data %>%
  mutate(quantile = ntile(price, 10)) %>%
  mutate(no_stay = number_of_reviews==0) %>% 
  group_by(quantile) %>%
  count(no_stay==1)%>% 
  mutate(prop = prop.table(n))%>% 
  ggplot(aes(x = quantile, y = prop, fill = `no_stay == 1`)) + geom_bar(stat = 'identity', position = 'dodge', alpha = 2/3) + geom_hline(yintercept = mean(raw_data$number_of_reviews == 0))
```


## Unreliability of "Reviews per Month"
We can see that the study uses a different number of total months for each listing when calculating "average reviews per month."
```{r, echo=FALSE, warning=FALSE, fig.height=5}
data_transformed <- readRDS("data_transformed.rds")
before_transform <- data_transformed %>% 
  filter(id == c(5447434, 30232758)) %>% 
  select(id, number_of_reviews, last_review, reviews_per_month)
```

## Normalized Average Reviews
<font size ="1">
$$\frac{\text{Days between July 8, 2019 and Last Review}}{30.42} = \text{Months Inactive} $$
$$\frac{\text{No. of Reviews}}{\text{Months Active + Months Inactive}} = \text{Reviews per Month}$$
$$\text{Months Active} = \min \left\{\frac{\text{No. of Reviews - (Reviews per Month)(Months Inactive)}}{\text{Reviews per Month}}, 1\right\}$$
$$\text{Normalized Average Reviews} = \frac{\text{Total Reviews}}{\text{Months Active}}$$
</font>

## Normalized Average Reviews
Through normalization, we recover the popularity of each listing during the time it was active. 
```{r, echo=FALSE, warning=FALSE, fig.height=5}
data_transformed %>% 
  filter(id == c(5447434, 30232758)) %>% 
  select(id, number_of_reviews, last_review, reviews_per_month, nrml_avg_reviews)
```

## Text Analysis
We identified all adjectives that occured in 10 or more listings (219 words). We then ran a linear regression of average reviews against these words, and identified all words with p-values below the Bonferonni adjustment of $\frac{0.05}{218}$. This left 18 words for further analysis.
```{r, echo=FALSE, warning=FALSE, fig.height=5}
text_model <- lm(nrml_avg_reviews~ . , data = data_transformed[, -c(1:6, 7:18, 20:21)])

pvalues <- data.frame(summary(text_model)$coefficients[,4])
words <- names(coef(text_model))
toplist <- as.data.frame(cbind(words, pvalues))
colnames(toplist) <- c("words", "pvalues")

# toplist %>% 
#   arrange(pvalues) %>% 
#   filter(pvalues<0.05/219)

```

## Hierarchical Model
```{r, echo=FALSE, warning=FALSE, fig.height=5}

model_hier <- lmer(nrml_avg_reviews~ (1|neighbourhood_group/neighbourhood)+price +dist_to_subway + room_type + gender + private + square + minute + close + stock + apt + sunny + spacious +deluxe + newly + walking + cozy + central + fast + huge + west + green, data = data_transformed)
#summary(model_heir) #You can see the coefficents here
#anova(model_heir) #You can see the p-values here
#coef(model_heir) #This is not that useful

#plot_summs(model_heir)


```


## Spatial Auto-correlation: Theater District

```{r, warning=FALSE, message=FALSE, echo= FALSE}
data <- readRDS("data_transformed.rds")
data %>% filter( neighbourhood == "Theater District" |neighbourhood == "Hell's Kitchen") %>% ggplot(aes(x  = latitude, y = longitude, color = neighbourhood)) + geom_density_2d(aes(fill = ..level..), geom= "polygon") + theme(legend.position = "none") + ggtitle("Hell's Kitchen and Theater District Density")

data %>% filter(neighbourhood == "Chinatown") %>% 
  ggplot(aes(x  = latitude, y = longitude)) + 
  geom_density2d(aes(color = stat(level)), geom="polygon") + 
  theme(legend.position = "none") + 
  ggtitle("Chinatown Density")
```

## Conditionally Autoregressive Model
The Leroux et. al. model:

Priors:

$$\phi_k| \phi_{-k}, W, \tau^2, \rho \sim N(\frac{\rho\sum_{i=1}^k w_{ki}\phi_i}{\rho\sum_{i=1}^k w_{ki} + 1-\rho}, \frac{\tau^2}{\rho\sum_{i=1}^k w_{ki} + 1-\rho})$$
$$\tau^2 \sim Inverse-Gamma(a,b)$$
$$\rho \sim Uniform(0,1)$$

This induces neighbor spatial correlation:

$$COR(\phi_k, \phi_j | \phi_{-kj}, W, \rho) =$$
$$\frac{\rho w_{kj}}{\sqrt{(\rho \sum_{i=1}^k w_{ki} + 1 - \rho)(\rho \sum_{i=1}^k w_{ki} + 1 - \rho }}$$

## Evidence of Auto-Correlation

```{r, warning=FALSE, message=FALSE, echo= FALSE}

data_r <- rbind(c("rho", 0.9072, "Bronx"), c("rho", 0.9277, "Manhattan"),  c("rho", 0.7474, "Queens"), c("rho", 0.7389, "Brooklyn"))
data_r <- data.frame(data_r)
names(data_r) <- c("Variables", "Value", "Borough")

data_r  %>% ggplot(aes(x=Borough,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Rho Coefficients")

```

## CAR Results Bronx

```{r, echo=FALSE, message=FALSE, warning=FALSE}

data <- readRDS("Coefficient_Data.rds")

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Bronx") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Bronx Coefficients (Reference: Allerton)")

```


## CAR Results Manhattan

```{r, echo=FALSE, message=FALSE, warning=FALSE}

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Manhattan") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Manhattan Coefficients (Reference: Battery Park City)")


```

## CAR Results Queens

```{r, echo=FALSE, message=FALSE, warning=FALSE}

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Queens") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ggtitle("Queens Coefficients (Reference: Arverne)")
```

## CAR Results Brooklyn

```{r, echo=FALSE, message=FALSE, warning=FALSE}

data%>% filter(Variables != "(Intercept)" & Variables != "price" & Variables != "dist_to_subway") %>% filter(Borough == "Brooklyn") %>% ggplot(aes(x=Variables,y=Value)) + geom_bar(stat="identity") + theme(axis.text.x = element_text(angle = 90, hjust = 1))+ ggtitle("Brooklyn Coefficients (Referene: Bath Beach)")
```



## Conclusions

## Improvements



